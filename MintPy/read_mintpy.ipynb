{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read results processed by MintPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:59:25.949717Z",
     "start_time": "2020-08-19T11:59:25.941292Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:51:08.500369Z",
     "start_time": "2020-08-19T11:51:08.492653Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_h5(fname, label):\n",
    "    with h5py.File(fname, 'r') as f:\n",
    "        atr = dict(f.attrs)\n",
    "        data = np.asarray(f[(label)])\n",
    "    return data, atr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**read velocity and mask files, return 4 colums data (num lon lat velocity), you also can save data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:51:11.484189Z",
     "start_time": "2020-08-19T11:51:11.467842Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def read_vel(vel_file, mask_file, out_vel_file=None):\n",
    "    # read velocity\n",
    "    vel, atr = read_h5(vel_file, 'velocity')\n",
    "    # get longitude and latitude of the upperleft corner\n",
    "    lon = float(atr['X_FIRST'])\n",
    "    lat = float(atr['Y_FIRST'])\n",
    "    # get interval of lonitude and latitude\n",
    "    lon_step = float(atr['X_STEP'])\n",
    "    lat_step = float(atr['Y_STEP'])\n",
    "    # generate latitude and longitude coordinates\n",
    "    lon_tmp = np.linspace(lon, lon + lon_step * vel.shape[1], vel.shape[1])\n",
    "    lat_tmp = np.linspace(lat, lat + lat_step * vel.shape[0], vel.shape[0])\n",
    "    lons, lats = np.meshgrid(lon_tmp, lat_tmp)\n",
    "    # read mask\n",
    "    mask, _ = read_h5(mask_file, 'mask')\n",
    "    # mask and reshape\n",
    "    lons = lons[mask].reshape((-1, 1))\n",
    "    lats = lats[mask].reshape((-1, 1))\n",
    "    vel = vel[mask].reshape((-1, 1))\n",
    "    # generate point ID\n",
    "    num = np.arange(vel.shape[0]).reshape((-1, 1))\n",
    "    # m/yr to mm/yr\n",
    "    vel *= 1000\n",
    "    # print some information\n",
    "    print('max velocity : ', np.max(vel))\n",
    "    print('min velocity : ', np.min(vel))\n",
    "    print('number of points : ', vel.shape[0])\n",
    "    # save data\n",
    "    out_data = np.hstack((num, lons, lats, vel))\n",
    "    if out_vel_file:\n",
    "        print('writing data to {}'.format(out_vel_file))\n",
    "        np.savetxt(out_vel_file, out_data, fmt='%4f')\n",
    "        print('done.')\n",
    "    return out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:39:01.774660Z",
     "start_time": "2020-08-18T04:39:01.725780Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# velocity = read_vel('geo_velocity.h5', 'geo_maskTempCoh.h5', 'vels.txt')\n",
    "velocity = read_vel('geo_velocity.h5', 'geo_maskTempCoh.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**random downsample data in [min, max], return 4 colums data (num lon lat velocity), you also can save data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:51:14.096006Z",
     "start_time": "2020-08-19T11:51:14.079719Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def random_downsample(data, min_vel, max_vel, rate, out_file=None):\n",
    "    if min_vel > max_vel:\n",
    "        tmp = min_vel\n",
    "        min_vel = max_vel\n",
    "        max_vel = tmp\n",
    "    #  vel <= min_vel\n",
    "    less_min = data[:, 3] <= min_vel\n",
    "    data_less_min = data[less_min, :]\n",
    "    print(f\"number of velocity < {min_vel} : {data_less_min.shape[0]}\")\n",
    "    # vel >= max_vel\n",
    "    more_max = data[:, 3] >= max_vel\n",
    "    data_more_max = data[more_max, :]\n",
    "    print(f\"number of velocity > {max_vel} : {data_more_max.shape[0]}\")\n",
    "    # vel > min_vel and vel < max_vel\n",
    "    min_max = (less_min == more_max)\n",
    "    data_min_max = data[min_max, :]\n",
    "    print(\n",
    "        f\"number of velocity in [{min_vel}, {max_vel}] : {data_min_max.shape[0]}\")\n",
    "    # downsample vel > min_vel and vel < max_vel\n",
    "    index = random.sample(range(data_min_max.shape[0]), int(\n",
    "        data_min_max.shape[0] * rate))\n",
    "    sampled_data = data_min_max[index, :]\n",
    "    # save data\n",
    "    out_data = np.vstack((data_less_min, data_more_max, sampled_data))\n",
    "    print('max velocity : ', np.max(out_data[:, 3]))\n",
    "    print('min velocity : ', np.min(out_data[:, 3]))\n",
    "    print('number of points : ', out_data.shape[0])\n",
    "    if out_file:\n",
    "        print('writing data to {}'.format(out_file))\n",
    "        np.savetxt(out_file, out_data, fmt='%4f')\n",
    "        print('done.')\n",
    "    return out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:41:02.760326Z",
     "start_time": "2020-08-18T04:41:02.674870Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vel_ds = random_downsample(velocity, 10, -10, 0.3, \"vels_ds.txt\")\n",
    "vel_ds = random_downsample(velocity, 10, -10, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read time-series and velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**read ts_file, vel_file, mask_file, return timeseries data(num lon lat vel disp1 disp2 ...) and date, you also can save data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:51:28.578950Z",
     "start_time": "2020-08-19T11:51:28.556773Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def read_ts(ts_file, vel_file, mask_file, out_vel_file=None, out_ts_file=None):\n",
    "    mask, _ = read_h5(mask_file, 'mask')\n",
    "    mask = np.asarray(mask)\n",
    "\n",
    "    vel, _ = read_h5(vel_file, 'velocity')\n",
    "    vel = np.asarray(vel) * 1000\n",
    "\n",
    "    date, _ = read_h5(ts_file, 'date')\n",
    "    date = date.astype(np.int64)\n",
    "    ts, atr = read_h5(ts_file, 'timeseries')\n",
    "    ts = np.asarray(ts)\n",
    "    ts = ts.reshape((date.shape[0], -1, 1)) * 1000\n",
    "\n",
    "    lon = float(atr['X_FIRST'])\n",
    "    lon_step = float(atr['X_STEP'])\n",
    "\n",
    "    lat = float(atr['Y_FIRST'])\n",
    "    lat_step = float(atr['Y_STEP'])\n",
    "\n",
    "    lon_tmp = np.linspace(lon, lon + lon_step * vel.shape[1], vel.shape[1])\n",
    "    lat_tmp = np.linspace(lat, lat + lat_step * vel.shape[0], vel.shape[0])\n",
    "\n",
    "    lons, lats = np.meshgrid(lon_tmp, lat_tmp)\n",
    "\n",
    "    lons = lons.reshape((-1, 1))\n",
    "    lats = lats.reshape((-1, 1))\n",
    "    vels = vel.reshape((-1, 1))\n",
    "    mask = mask.reshape((-1, 1))\n",
    "\n",
    "    lons = lons[mask].reshape((-1, 1))\n",
    "    lats = lats[mask].reshape((-1, 1))\n",
    "    vels = vels[mask].reshape((-1, 1))\n",
    "    num = np.arange(lons.shape[0]).reshape((-1, 1))\n",
    "\n",
    "    out_vel = np.hstack((num, lons, lats, vels))\n",
    "    if out_vel_file:\n",
    "        # save lon, lat, velocity\n",
    "        print('writing data to {}'.format(out_vel_file))\n",
    "        np.savetxt(out_vel_file, out_vel, fmt='%4f')\n",
    "        print('done.')\n",
    "\n",
    "    out_ts = out_vel\n",
    "    for i in range(ts.shape[0]):\n",
    "        data = ts[i]\n",
    "        out_ts = np.hstack((out_ts, data[mask].reshape((-1, 1))))\n",
    "\n",
    "    tmp = out_ts[:, 4:]\n",
    "    tmp = tmp - tmp[:, 0].reshape((-1, 1))\n",
    "    tmp = np.hstack((out_vel, tmp))\n",
    "\n",
    "    out_ts = tmp\n",
    "    if out_ts_file:\n",
    "        # save lon, lat, vel, disp\n",
    "        print('writing data to {}'.format(out_ts_file))\n",
    "        np.savetxt(out_ts_file, out_ts, fmt='%4f')\n",
    "        print('done.')\n",
    "\n",
    "    return out_ts, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:52:17.504706Z",
     "start_time": "2020-08-19T11:52:12.047684Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/media/ly/file/读取MintPy结果')\n",
    "ts = 'geo_timeseries_tropHgt_ramp_demErr.h5'\n",
    "vel = 'geo_velocity.h5'\n",
    "mask = 'geo_maskTempCoh.h5'\n",
    "\n",
    "# ts_data, date =read_ts(ts, vel, mask, 'vel.txt', 'ts.txt')\n",
    "ts_data, date = read_ts(ts, vel, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T11:26:23.866432Z",
     "start_time": "2020-08-18T11:26:23.737047Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampled_ts = random_downsample(ts_data, 10, -10, 0.3, \"ts_ds.txt\")\n",
    "sampled_ts = random_downsample(ts_data, 19, -10, 0.17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for making kmz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**timeseries data format:**\n",
    "```plaintext\n",
    "-1   -1   -1   -1   date1  date2  date3 ...\n",
    "num1 lon1 lat1 vel1 disp11 disp12 disp13 ...\n",
    "num2 lon2 lat2 vel2 disp21 disp22 disp23 ...\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:52:30.587637Z",
     "start_time": "2020-08-19T11:52:30.577763Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def prep_data_for_kmz(ts_data, date, out_vel_file, out_ts_file):\n",
    "    first_line = np.asarray([[-1, -1, -1, -1]])\n",
    "    first_line = np.hstack((first_line, date.reshape((1, -1))))\n",
    "    out_ts = np.vstack((first_line, ts_data))\n",
    "    out_vel = ts_data[0:, 0:4]\n",
    "\n",
    "    print('writing data to {}'.format(out_ts_file))\n",
    "    np.savetxt(out_ts_file, out_ts, fmt='%4f')\n",
    "    print('done.')\n",
    "    print('writing data to {}'.format(out_vel_file))\n",
    "    np.savetxt(out_vel_file, out_vel, fmt='%4f')\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:52:58.796029Z",
     "start_time": "2020-08-19T11:52:44.519728Z"
    }
   },
   "outputs": [],
   "source": [
    "prep_data_for_kmz(ts_data, date, 'vel.txt', 'ts.txt')\n",
    "# prep_data_for_kmz(sampled_ts, date, 'vel_ds.txt', 'ts_ds.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make kmz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T11:29:38.994845Z",
     "start_time": "2020-08-18T11:29:19.085469Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 make_kmz_timeseries.py -t ts_ds.txt -o ts_ds10.kmz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:50:36.925463Z",
     "start_time": "2020-08-18T07:50:28.121263Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 make_kmz.py -v vel_ds.txt -o vel_ds.kmz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot timeseries displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get displacement by number, must use complete ts_data (not downsampled)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T12:05:32.238109Z",
     "start_time": "2020-08-19T12:05:32.224289Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def date2str(date):\n",
    "    date_str = []\n",
    "    for i in date:\n",
    "        date_str.append(str(i))\n",
    "    return date_str\n",
    "\n",
    "\n",
    "def plot_displacement(num_list, ts_data, date, aspect=0.2, figsize=(15, 7), y_lim=[-100, 100], fig_name=None):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_title('time series displacement', fontsize=40)\n",
    "    ax.set_xlabel('date', fontsize=30)\n",
    "    ax.set_ylabel('displacrment (mm)', fontsize=30)\n",
    "\n",
    "    ax.set_ylim(y_lim[0], y_lim[1])\n",
    "    ax.set_aspect(aspect)\n",
    "    ax.minorticks_on()\n",
    "    ax.xaxis.grid(True, which='both')\n",
    "    ax.xaxis.set_tick_params(rotation=30, labelsize=15)\n",
    "    ax.yaxis.grid(True, which='major')\n",
    "    ax.yaxis.set_tick_params(rotation=0, labelsize=15)\n",
    "    ax.set_xmargin(0.02)\n",
    "\n",
    "    date = date2str(date)\n",
    "\n",
    "    for num in num_list:\n",
    "        disp = ts_data[num, 4:]\n",
    "        ax.plot(date, disp, label=str(num), marker='o')\n",
    "        ax.xaxis.set_ticks(date[::4])\n",
    "    ax.legend(loc='best', fontsize=20, ncol=2)\n",
    "    fig.show()\n",
    "    if fig_name:\n",
    "        fig.savefig(fig_name, dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T12:06:38.300439Z",
     "start_time": "2020-08-19T12:06:37.657063Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_list = [113174]\n",
    "plot_displacement(num_list, ts_data, date, aspect=0.2,\n",
    "                  figsize=(30, 15), y_lim=[-150, 10], fig_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cut velocity and timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**find points inside the polygon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:44:45.559247Z",
     "start_time": "2020-08-19T11:44:45.545900Z"
    }
   },
   "outputs": [],
   "source": [
    "def intersect(point, s_point, e_point):\n",
    "    if s_point[1] == e_point[1]:  # parallel and coincident with the ray，s_point coincides with s_point\n",
    "        return False\n",
    "    if s_point[1] > point[1] and e_point[1] > point[1]:  # line segment is above the ray\n",
    "        return False\n",
    "    if s_point[1] < point[1] and e_point[1] < point[1]:  # line segment under the ray\n",
    "        return False\n",
    "    if s_point[1] == point[1] and e_point[1] > point[1]:  # point coincides with s_point\n",
    "        return False\n",
    "    if e_point[1] == point[1] and s_point[1] > point[1]:  # point coincides with e_point\n",
    "        return False\n",
    "    # line segment is to the left of the ray\n",
    "    if s_point[0] < point[0] and e_point[1] < point[1]:\n",
    "        return False\n",
    "\n",
    "    xseg = e_point[0]-(e_point[0]-s_point[0])*(e_point[1]-point[1]) / \\\n",
    "        (e_point[1]-s_point[1])  # find the intersection\n",
    "    if xseg < point[0]:  # intersection is to the left of point\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def inpolygon(point, polygon):\n",
    "    num = 0  # number of intersection\n",
    "    for i in range(len(polygon)-1):\n",
    "        if intersect(point, polygon[i], polygon[i+1]):\n",
    "            num += 1\n",
    "    return True if num % 2 == 1 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kml2polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:44:56.457692Z",
     "start_time": "2020-08-19T11:44:56.452819Z"
    }
   },
   "outputs": [],
   "source": [
    "def kml2polygon(kml_file, polygon_file):\n",
    "    cmd_str = f\"gmt kml2gmt {kml_file} | awk 'NR>1' > {polygon_file}\"\n",
    "    os.system(cmd_str)\n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:45:18.566505Z",
     "start_time": "2020-08-19T11:45:18.487699Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('/media/ly/file/读取MintPy结果/cut')\n",
    "kml2polygon('cut1.kml', 'cut1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cut velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:45:44.469056Z",
     "start_time": "2020-08-19T11:45:44.464696Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut_vel(polygon_file, vel_file, out_vel_file):\n",
    "    polygon = np.loadtxt(polygon_file)\n",
    "    vel = np.loadtxt(vel_file)\n",
    "    out_data = np.arange(vel.shape[1])\n",
    "    for line in vel:\n",
    "        if inpolygon(line[1:3], polygon):\n",
    "            out_data = np.vstack((out_data, line))\n",
    "    np.savetxt(out_vel_file, out_data[1:, :], fmt='%4f')\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_vel('cut1.txt', 'vel.txt', 'vel_cut1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 make_kmz2.py -v vel_cut1.txt -o vel_cut1.kmz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cut timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:53:34.787982Z",
     "start_time": "2020-08-19T11:53:34.779506Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut_ts(polygon_file, ts_file, out_ts_file):\n",
    "    polygon = np.loadtxt(polygon_file)\n",
    "    data = np.loadtxt(ts_file)\n",
    "    ts = data[1:, :]\n",
    "    out_data = data[0, :]\n",
    "    for line in ts:\n",
    "        if inpolygon(line[1:3], polygon):\n",
    "            out_data = np.vstack((out_data, line))\n",
    "    np.savetxt(out_ts_file, out_data, fmt='%4f')\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:55:54.848493Z",
     "start_time": "2020-08-19T11:53:54.022125Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('/media/ly/file/读取MintPy结果/cut')\n",
    "cut_ts('cut1.txt', 'ts.txt', 'ts_cut1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:03:39.937300Z",
     "start_time": "2020-08-19T13:03:37.767445Z"
    }
   },
   "outputs": [],
   "source": [
    "!python3 make_kmz_timeseries2.py -t ts_cut1.txt -o ts_cut1.kmz -s 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}